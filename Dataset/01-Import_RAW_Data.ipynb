{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "\n",
    "def clean_html_entities(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'&lrm;|&rlm;', '', text, flags=re.IGNORECASE)\n",
    "    text = html.unescape(text)\n",
    "    text = text.replace('&nbsp;', ' ')\n",
    "    return text\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<br\\s*/?>', '\\n', text, flags=re.IGNORECASE)  # Keep as newline\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Remove other tags\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(r\"ى\", \"ي\", text)\n",
    "    text = re.sub(r\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(r\"ئ\", \"ء\", text)\n",
    "    text = re.sub(r\"ة\", \"ه\", text)\n",
    "    text = re.sub(r\"گ\", \"ك\", text)\n",
    "    return text\n",
    "\n",
    "def clean_for_search(text):\n",
    "    \"\"\"Final cleaning with placeholder for standalone diacritics.\"\"\"\n",
    "    text = str(text)\n",
    "    \n",
    "    # Replace standalone diacritics with placeholder\n",
    "    text = re.sub(r'\\s+([\\u064B-\\u065F])\\s+', ' _ ', text)\n",
    "    \n",
    "    # Normalize Arabic letters\n",
    "    text = re.sub(r\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(r\"ى\", \"ي\", text)\n",
    "    text = re.sub(r\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(r\"ئ\", \"ء\", text)\n",
    "    text = re.sub(r\"ة\", \"ه\", text)\n",
    "    text = re.sub(r\"گ\", \"ك\", text)\n",
    "    \n",
    "    # Remove diacritics and tatweel\n",
    "    text = re.sub(r'[\\u0640\\u064B-\\u065F\\u0670]', '', text)\n",
    "    \n",
    "    # Collapse spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11773 rows.\n",
      "After exploding lines: 11773 rows\n"
     ]
    }
   ],
   "source": [
    "# Load Excel\n",
    "file_path = \"shbm_poetry.xlsx\"\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "print(f\"Loaded {len(df)} rows.\")\n",
    "\n",
    "df['Text content'] = df['Text content'].astype(str)\n",
    "df['Title'] = df['Title'].astype(str)\n",
    "df['ROW_ID'] = df.index + 1\n",
    "\n",
    "invisible_chars_pattern = r'[\\u200B\\u200C\\u200D\\u200E\\u200F\\u2066\\u2067\\u2068\\u2069\\u202A\\u202B\\u202C\\u202D\\u202E\\uFEFF]'\n",
    "\n",
    "# Split multi-line cells on newlines (from <br /> conversion)\n",
    "df['Text content'] = df['Text content'].str.split('\\n')\n",
    "df = df.explode('Text content').reset_index(drop=True)\n",
    "df['ROW_ID'] = df.index + 1\n",
    "\n",
    "print(f\"After exploding lines: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning HTML and normalizing...\n",
      "Dataset has 11773 rows.\n",
      "                            Text content            Title  ROW_ID\n",
      "0        حبيـبتي حالـي من الشــوق دانــي  لا تسـأل مجـرّب       1\n",
      "1     أشــرّق بحـبّــك .. واعـوّد أغـرّب  لا تسـأل مجـرّب       2\n",
      "2                                         لا تسـأل مجـرّب       3\n",
      "3      أنـانـي فْـ وصـلك لـكـن يالأنـاني  لا تسـأل مجـرّب       4\n",
      "4  تـرى الأنانـيّـه فْـ طـبـعـك تـخــرّب  لا تسـأل مجـرّب       5\n",
      "5                                         لا تسـأل مجـرّب       6\n",
      "6           لحظات حبّـك حطّـمت لي كـياني  لا تسـأل مجـرّب       7\n",
      "7        والحزن من بين الـمحـاني تـسـرّب  لا تسـأل مجـرّب       8\n",
      "8                                         لا تسـأل مجـرّب       9\n",
      "9       تـسـرّب وصـكّـت عـلـيه الـمـحاني  لا تسـأل مجـرّب      10\n"
     ]
    }
   ],
   "source": [
    "# Clean HTML and normalize\n",
    "print(\"Cleaning HTML and normalizing...\")\n",
    "\n",
    "df['Text content'] = (df['Text content']\n",
    "                      .apply(clean_html_entities)\n",
    "                      .apply(strip_html_tags)\n",
    "                      .apply(lambda x: re.sub(invisible_chars_pattern, '', x)))\n",
    "\n",
    "df['Title'] = (df['Title']\n",
    "               .apply(clean_html_entities)\n",
    "               .apply(lambda x: re.sub(invisible_chars_pattern, '', x)))\n",
    "\n",
    "df['Title'] = df['Title'].replace(['nan', 'NaN', ''], pd.NA).ffill().fillna(\"Unknown\")\n",
    "\n",
    "print(f\"Dataset has {len(df)} rows.\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing nan: 11357 rows\n"
     ]
    }
   ],
   "source": [
    "# Remove only actual 'nan' text, keep empty lines (stanza breaks)\n",
    "nan_mask = df['Text content'].str.lower() == 'nan'\n",
    "df = df[~nan_mask].copy()\n",
    "\n",
    "print(f\"After removing nan: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total poems: 353\n",
      "    ROW_ID  poem_ID            Title                             Text content\n",
      "0        1        1  لا تسـأل مجـرّب          حبيـبتي حالـي من الشــوق دانــي\n",
      "1        2        1  لا تسـأل مجـرّب       أشــرّق بحـبّــك .. واعـوّد أغـرّب\n",
      "2        3        1  لا تسـأل مجـرّب                                         \n",
      "3        4        1  لا تسـأل مجـرّب        أنـانـي فْـ وصـلك لـكـن يالأنـاني\n",
      "4        5        1  لا تسـأل مجـرّب    تـرى الأنانـيّـه فْـ طـبـعـك تـخــرّب\n",
      "5        6        1  لا تسـأل مجـرّب                                         \n",
      "6        7        1  لا تسـأل مجـرّب             لحظات حبّـك حطّـمت لي كـياني\n",
      "7        8        1  لا تسـأل مجـرّب          والحزن من بين الـمحـاني تـسـرّب\n",
      "8        9        1  لا تسـأل مجـرّب                                         \n",
      "9       10        1  لا تسـأل مجـرّب         تـسـرّب وصـكّـت عـلـيه الـمـحاني\n",
      "10      11        1  لا تسـأل مجـرّب      كـنّـه لـوصـلك بالـجـروح يْـتـقـرّب\n",
      "11      12        1  لا تسـأل مجـرّب                                         \n",
      "12      13        1  لا تسـأل مجـرّب       يا مْعـرّب الأنـسـاب خـدر العـياني\n",
      "13      14        1  لا تسـأل مجـرّب    سِـلْـم العـرب لا تجهـله يـالـمـعـرّب\n",
      "14      15        1  لا تسـأل مجـرّب                                         \n",
      "15      16        1  لا تسـأل مجـرّب            شـربت حـبّـك لين فـاض الحناني\n",
      "16      17        1  لا تسـأل مجـرّب           وقامـت عروقي من غـلاك تْـشـرّب\n",
      "17      18        1  لا تسـأل مجـرّب                                         \n",
      "19      20        2    ثــلاث مـرّات    ثـــلاث مـرّات .. وانـت تـدوّر فـراقي\n",
      "20      21        2    ثــلاث مـرّات  وثــلاث مـرّات .. وانـا اقـول لا ترحــل\n"
     ]
    }
   ],
   "source": [
    "# Assign poem_ID based on title groups\n",
    "df['poem_ID'] = (df['Title'] != df['Title'].shift()).cumsum()\n",
    "\n",
    "print(f\"Total poems: {df['poem_ID'].nunique()}\")\n",
    "print(df[['ROW_ID', 'poem_ID', 'Title', 'Text content']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final columns:\n",
      "['Poem_line_Raw', 'Title_Raw', 'ROW_ID', 'poem_ID', 'Poem_line_cleaned', 'Title_cleaned']\n"
     ]
    }
   ],
   "source": [
    "# Create cleaned columns with placeholder for search\n",
    "df['Poem_line_cleaned'] = df['Text content'].apply(clean_for_search)\n",
    "df['Title_cleaned'] = df['Title'].apply(clean_for_search)\n",
    "\n",
    "# Rename for clarity\n",
    "df = df.rename(columns={\n",
    "    'Text content': 'Poem_line_Raw',\n",
    "    'Title': 'Title_Raw'\n",
    "})\n",
    "\n",
    "print(\"\\nFinal columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 odd-length poems\n",
      "   poem_ID  length        Title_cleaned  min_ROW_ID\n",
      "0      180      21           مرثيه زايد        7161\n",
      "1      239     121          هدهد سليمان        9589\n",
      "2      252      47             عام زايد       10199\n",
      "3      288      47  عجايب وشنذاره وغياث       10981\n"
     ]
    }
   ],
   "source": [
    "# Check for odd-length poems\n",
    "# Exclude empty lines (stanza breaks) from counting\n",
    "df_non_empty = df[df['Poem_line_cleaned'].str.len() > 0]\n",
    "poem_lengths = df_non_empty.groupby('poem_ID').size().reset_index(name='length')\n",
    "\n",
    "odd_poems = poem_lengths[poem_lengths['length'] % 2 == 1]\n",
    "\n",
    "if len(odd_poems) > 0:\n",
    "    odd_with_titles = odd_poems.merge(\n",
    "        df.groupby('poem_ID')['Title_cleaned'].first().reset_index(),\n",
    "        on='poem_ID'\n",
    "    )\n",
    "    odd_with_titles['min_ROW_ID'] = odd_with_titles['poem_ID'].map(\n",
    "        df.groupby('poem_ID')['ROW_ID'].min()\n",
    "    )\n",
    "    \n",
    "    odd_with_titles.to_csv('odd_length_poems.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"Found {len(odd_poems)} odd-length poems\")\n",
    "    print(odd_with_titles.head(10))\n",
    "else:\n",
    "    print(\"✓ All poems have even line counts!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved 11357 rows to shbm_poetry_CLEANED_FINAL.csv\n",
      "\n",
      "Final stats:\n",
      "  Total rows: 11357\n",
      "  Total poems: 353\n",
      "  Avg lines per poem: 32.2\n"
     ]
    }
   ],
   "source": [
    "# Save final cleaned dataset\n",
    "output_cols = ['ROW_ID', 'poem_ID', 'Poem_line_Raw', 'Title_Raw', 'Poem_line_cleaned', 'Title_cleaned']\n",
    "df[output_cols].to_csv('shbm_poetry_CLEANED_FINAL.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n✓ Saved {len(df)} rows to shbm_poetry_CLEANED_FINAL.csv\")\n",
    "print(f\"\\nFinal stats:\")\n",
    "print(f\"  Total rows: {len(df)}\")\n",
    "print(f\"  Total poems: {df['poem_ID'].nunique()}\")\n",
    "print(f\"  Avg lines per poem: {len(df) / df['poem_ID'].nunique():.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
