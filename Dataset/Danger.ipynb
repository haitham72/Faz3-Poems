{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('./CSV/FAZ3_POEMS_Exact_Search - cleaned Full_poems.csv')\n",
    "target_csv = pd.read_csv('./CSV/FAZ3_POEMS_Exact_Search - Exact_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552f07c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ARABIC POETRY CSV LINE REORDERER\n",
      "======================================================================\n",
      "\n",
      "⚠ Dropping 1 guide rows with non-numeric poem_id\n",
      "\n",
      "Guide poems: 352\n",
      "Target rows: 4214\n",
      "Common poem_ids: 351\n",
      "Mapping entries created: 4189\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m target_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./CSV/FAZ3_POEMS_Exact_Search - Exact_search.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfix_csv_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguide_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 55\u001b[0m, in \u001b[0;36mfix_csv_order\u001b[0;34m(guide_path, target_path, output_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m     key \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoem_id\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoem_line_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m line_order_map\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;241m999999\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m target_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline_order\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Calculate matching statistics\u001b[39;00m\n\u001b[1;32m     58\u001b[0m matched \u001b[38;5;241m=\u001b[39m (target_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline_order\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m999999\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/pandas/core/frame.py:10401\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10387\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10389\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10391\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10399\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10400\u001b[0m )\n\u001b[0;32m> 10401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m, in \u001b[0;36mfix_csv_order.<locals>.get_order\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_order\u001b[39m(row):\n\u001b[0;32m---> 52\u001b[0m     key \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoem_id\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPoem_line_cleaned\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m())\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m line_order_map\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;241m999999\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fix_csv_order(guide_path, target_path, output_path):\n",
    "    \"\"\"\n",
    "    Reorder target CSV rows to match guide CSV's correct poem line order.\n",
    "    \n",
    "    Args:\n",
    "        guide_path: Path to guide CSV (has full poems in multi-line cells)\n",
    "        target_path: Path to target CSV (has individual lines as rows, wrong order)\n",
    "        output_path: Path to save fixed CSV\n",
    "    \"\"\"\n",
    "    # Read CSVs\n",
    "    guide_df = pd.read_csv(guide_path)\n",
    "    target_df = pd.read_csv(target_path)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ARABIC POETRY CSV LINE REORDERER\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Convert guide poem_id to int, handling non-numeric values\n",
    "    guide_df['poem_id'] = pd.to_numeric(guide_df['poem_id'], errors='coerce')\n",
    "    invalid_rows = guide_df['poem_id'].isna().sum()\n",
    "    \n",
    "    if invalid_rows > 0:\n",
    "        print(f\"\\n⚠ Dropping {invalid_rows} guide rows with non-numeric poem_id\")\n",
    "        guide_df = guide_df.dropna(subset=['poem_id'])\n",
    "    \n",
    "    guide_df['poem_id'] = guide_df['poem_id'].astype(int)\n",
    "    \n",
    "    # Show statistics\n",
    "    common_poems = len(set(guide_df['poem_id']) & set(target_df['poem_id']))\n",
    "    print(f\"\\nGuide poems: {len(guide_df)}\")\n",
    "    print(f\"Target rows: {len(target_df)}\")\n",
    "    print(f\"Common poem_ids: {common_poems}\")\n",
    "    \n",
    "    # Build mapping: (poem_id, line_text) -> correct_line_order\n",
    "    line_order_map = {}\n",
    "    \n",
    "    for _, guide_row in guide_df.iterrows():\n",
    "        poem_id = guide_row['poem_id']\n",
    "        full_poem = str(guide_row['Poem_line_cleaned'])\n",
    "        lines = [l.strip() for l in full_poem.split('\\n') if l.strip()]\n",
    "        \n",
    "        for line_num, line in enumerate(lines, start=1):\n",
    "            key = (poem_id, line)\n",
    "            line_order_map[key] = line_num\n",
    "    \n",
    "    print(f\"Mapping entries created: {len(line_order_map)}\")\n",
    "    \n",
    "    # Assign correct line order to each target row\n",
    "    def get_order(row):\n",
    "        key = (row['poem_id'], row['Poem_line_cleaned'].strip())\n",
    "        return line_order_map.get(key, 999999)\n",
    "    \n",
    "    target_df['line_order'] = target_df.apply(get_order, axis=1)\n",
    "    \n",
    "    # Calculate matching statistics\n",
    "    matched = (target_df['line_order'] != 999999).sum()\n",
    "    unmatched = (target_df['line_order'] == 999999).sum()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"MATCHING RESULTS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"✓ Matched: {matched}/{len(target_df)} ({100*matched/len(target_df):.1f}%)\")\n",
    "    print(f\"✗ Unmatched: {unmatched}\")\n",
    "    \n",
    "    # Show before/after for poem 1\n",
    "    test_poem_id = 1\n",
    "    if test_poem_id in target_df['poem_id'].values:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"POEM {test_poem_id} - BEFORE (wrong order)\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Get original order before sorting\n",
    "        original_target = pd.read_csv(target_path)\n",
    "        poem1_before = original_target[original_target['poem_id'] == test_poem_id]\n",
    "        for _, row in poem1_before.iterrows():\n",
    "            print(f\"Row_ID {row['Row_ID']}: {row['Poem_line_cleaned'][:55]}...\")\n",
    "    \n",
    "    # Sort by poem_id first, then by correct line order\n",
    "    target_df = target_df.sort_values(['poem_id', 'line_order']).reset_index(drop=True)\n",
    "    \n",
    "    # Renumber Row_ID globally from 1\n",
    "    target_df['Row_ID'] = range(1, len(target_df) + 1)\n",
    "    \n",
    "    # Drop helper column\n",
    "    target_df = target_df.drop('line_order', axis=1)\n",
    "    \n",
    "    # Save fixed CSV\n",
    "    target_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    # Show after for poem 1\n",
    "    if test_poem_id in target_df['poem_id'].values:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"POEM {test_poem_id} - AFTER (correct order)\")\n",
    "        print(f\"{'='*70}\")\n",
    "        poem1_after = target_df[target_df['poem_id'] == test_poem_id]\n",
    "        for _, row in poem1_after.iterrows():\n",
    "            print(f\"Row_ID {row['Row_ID']}: {row['Poem_line_cleaned'][:55]}...\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"✓ SUCCESS! Fixed CSV saved to: {output_path}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return target_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    guide_file = \"./CSV/FAZ3_POEMS_Exact_Search - cleaned Full_poems.csv\"\n",
    "    target_file = \"./CSV/FAZ3_POEMS_Exact_Search - Exact_search.csv\"\n",
    "    output_file = \"fixed.csv\"\n",
    "    \n",
    "    result = fix_csv_order(guide_file, target_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eaa7274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ARABIC POETRY CSV LINE REORDERER\n",
      "======================================================================\n",
      "\n",
      "⚠ Dropping 1 guide rows with non-numeric poem_id\n",
      "⚠ Warning: 1 rows in target have missing Poem_line_cleaned\n",
      "  These rows will be placed at the end\n",
      "\n",
      "Guide poems: 352\n",
      "Target rows: 4214\n",
      "Common poem_ids: 351\n",
      "Mapping entries created: 4189\n",
      "\n",
      "======================================================================\n",
      "MATCHING RESULTS\n",
      "======================================================================\n",
      "✓ Matched: 4180/4214 (99.2%)\n",
      "✗ Unmatched: 34\n",
      "\n",
      "Unmatched rows will be sorted to the end\n",
      "\n",
      "First 3 unmatched rows:\n",
      "  poem_id=2.0, Row_ID=15: اصعب سؤال ف حياه العاشق الشاقي      اللي طرحته علي...\n",
      "  poem_id=14.0, Row_ID=172: السؤال اللي يراودني علي كل اتجاه      عند مثلك سلع...\n",
      "  poem_id=68.0, Row_ID=967: والحين من شهرين من صار ماصار      وانا اتمني يا حب...\n",
      "\n",
      "======================================================================\n",
      "POEM 1 - BEFORE (wrong order)\n",
      "======================================================================\n",
      "Row_ID 1: اناني ف وصلك لكن يالاناني      تري الانانيه ف طبعك تخرب...\n",
      "Row_ID 2: لحظات حبك حطمت لي كياني      والحزن من بين المحاني تسرب...\n",
      "Row_ID 3: حبيبتي حالي من الشوق داني      اشرق بحبك .. واعود اغرب...\n",
      "Row_ID 4: تسرب وصكت عليه المحاني      كنه لوصلك بالجروح يتقرب...\n",
      "Row_ID 5: شربت حبك لين فاض الحناني      وقامت عروقي من غلاك تشرب...\n",
      "Row_ID 6: يا معرب الانساب خدر العياني      سلم العرب لا تجهله يال...\n",
      "\n",
      "======================================================================\n",
      "POEM 1 - AFTER (correct order)\n",
      "======================================================================\n",
      "Row_ID 1: حبيبتي حالي من الشوق داني      اشرق بحبك .. واعود اغرب...\n",
      "Row_ID 2: اناني ف وصلك لكن يالاناني      تري الانانيه ف طبعك تخرب...\n",
      "Row_ID 3: لحظات حبك حطمت لي كياني      والحزن من بين المحاني تسرب...\n",
      "Row_ID 4: تسرب وصكت عليه المحاني      كنه لوصلك بالجروح يتقرب...\n",
      "Row_ID 5: يا معرب الانساب خدر العياني      سلم العرب لا تجهله يال...\n",
      "Row_ID 6: شربت حبك لين فاض الحناني      وقامت عروقي من غلاك تشرب...\n",
      "\n",
      "======================================================================\n",
      "✓ SUCCESS! Fixed CSV saved to: fixed.csv\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fix_csv_order(guide_path, target_path, output_path):\n",
    "    \"\"\"\n",
    "    Reorder target CSV rows to match guide CSV's correct poem line order.\n",
    "    \"\"\"\n",
    "    # Read CSVs\n",
    "    guide_df = pd.read_csv(guide_path)\n",
    "    target_df = pd.read_csv(target_path)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ARABIC POETRY CSV LINE REORDERER\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Convert guide poem_id to int, handling non-numeric values\n",
    "    guide_df['poem_id'] = pd.to_numeric(guide_df['poem_id'], errors='coerce')\n",
    "    invalid_rows = guide_df['poem_id'].isna().sum()\n",
    "    \n",
    "    if invalid_rows > 0:\n",
    "        print(f\"\\n⚠ Dropping {invalid_rows} guide rows with non-numeric poem_id\")\n",
    "        guide_df = guide_df.dropna(subset=['poem_id'])\n",
    "    \n",
    "    guide_df['poem_id'] = guide_df['poem_id'].astype(int)\n",
    "    \n",
    "    # Check for missing values in target\n",
    "    missing_lines = target_df['Poem_line_cleaned'].isna().sum()\n",
    "    if missing_lines > 0:\n",
    "        print(f\"⚠ Warning: {missing_lines} rows in target have missing Poem_line_cleaned\")\n",
    "        print(f\"  These rows will be placed at the end\")\n",
    "    \n",
    "    # Show statistics\n",
    "    common_poems = len(set(guide_df['poem_id']) & set(target_df['poem_id']))\n",
    "    print(f\"\\nGuide poems: {len(guide_df)}\")\n",
    "    print(f\"Target rows: {len(target_df)}\")\n",
    "    print(f\"Common poem_ids: {common_poems}\")\n",
    "    \n",
    "    # Build mapping: (poem_id, line_text) -> correct_line_order\n",
    "    line_order_map = {}\n",
    "    \n",
    "    for _, guide_row in guide_df.iterrows():\n",
    "        poem_id = guide_row['poem_id']\n",
    "        full_poem = str(guide_row['Poem_line_cleaned'])\n",
    "        lines = [l.strip() for l in full_poem.split('\\n') if l.strip()]\n",
    "        \n",
    "        for line_num, line in enumerate(lines, start=1):\n",
    "            key = (poem_id, line)\n",
    "            line_order_map[key] = line_num\n",
    "    \n",
    "    print(f\"Mapping entries created: {len(line_order_map)}\")\n",
    "    \n",
    "    # Assign correct line order to each target row\n",
    "    def get_order(row):\n",
    "        # Handle missing/NaN values\n",
    "        if pd.isna(row['Poem_line_cleaned']):\n",
    "            return 999999\n",
    "        \n",
    "        key = (row['poem_id'], str(row['Poem_line_cleaned']).strip())\n",
    "        return line_order_map.get(key, 999999)\n",
    "    \n",
    "    target_df['line_order'] = target_df.apply(get_order, axis=1)\n",
    "    \n",
    "    # Calculate matching statistics\n",
    "    matched = (target_df['line_order'] != 999999).sum()\n",
    "    unmatched = (target_df['line_order'] == 999999).sum()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"MATCHING RESULTS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"✓ Matched: {matched}/{len(target_df)} ({100*matched/len(target_df):.1f}%)\")\n",
    "    print(f\"✗ Unmatched: {unmatched}\")\n",
    "    \n",
    "    if unmatched > 0:\n",
    "        print(f\"\\nUnmatched rows will be sorted to the end\")\n",
    "        # Show some unmatched examples\n",
    "        unmatched_samples = target_df[target_df['line_order'] == 999999].head(3)\n",
    "        print(\"\\nFirst 3 unmatched rows:\")\n",
    "        for _, row in unmatched_samples.iterrows():\n",
    "            line_text = row['Poem_line_cleaned'] if pd.notna(row['Poem_line_cleaned']) else \"[MISSING]\"\n",
    "            print(f\"  poem_id={row['poem_id']}, Row_ID={row['Row_ID']}: {str(line_text)[:50]}...\")\n",
    "    \n",
    "    # Show before/after for poem 1\n",
    "    test_poem_id = 1\n",
    "    if test_poem_id in target_df['poem_id'].values:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"POEM {test_poem_id} - BEFORE (wrong order)\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Get original order before sorting\n",
    "        original_target = pd.read_csv(target_path)\n",
    "        poem1_before = original_target[original_target['poem_id'] == test_poem_id]\n",
    "        for _, row in poem1_before.iterrows():\n",
    "            line = row['Poem_line_cleaned'] if pd.notna(row['Poem_line_cleaned']) else \"[MISSING]\"\n",
    "            print(f\"Row_ID {row['Row_ID']}: {str(line)[:55]}...\")\n",
    "    \n",
    "    # Sort by poem_id first, then by correct line order\n",
    "    target_df = target_df.sort_values(['poem_id', 'line_order']).reset_index(drop=True)\n",
    "    \n",
    "    # Renumber Row_ID globally from 1\n",
    "    target_df['Row_ID'] = range(1, len(target_df) + 1)\n",
    "    \n",
    "    # Drop helper column\n",
    "    target_df = target_df.drop('line_order', axis=1)\n",
    "    \n",
    "    # Save fixed CSV\n",
    "    target_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    # Show after for poem 1\n",
    "    if test_poem_id in target_df['poem_id'].values:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"POEM {test_poem_id} - AFTER (correct order)\")\n",
    "        print(f\"{'='*70}\")\n",
    "        poem1_after = target_df[target_df['poem_id'] == test_poem_id]\n",
    "        for _, row in poem1_after.iterrows():\n",
    "            line = row['Poem_line_cleaned'] if pd.notna(row['Poem_line_cleaned']) else \"[MISSING]\"\n",
    "            print(f\"Row_ID {row['Row_ID']}: {str(line)[:55]}...\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"✓ SUCCESS! Fixed CSV saved to: {output_path}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return target_df\n",
    "\n",
    "\n",
    "# Run\n",
    "guide_file = \"./CSV/FAZ3_POEMS_Exact_Search - cleaned Full_poems.csv\"\n",
    "target_file = \"./CSV/FAZ3_POEMS_Exact_Search - Exact_search.csv\"\n",
    "output_file = \"fixed.csv\"\n",
    "\n",
    "result = fix_csv_order(guide_file, target_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
