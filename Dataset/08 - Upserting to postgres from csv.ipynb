{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e651e6d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'دين'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Anaconda\\envs\\cudas\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'دين'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps([value_str], ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Apply fixes to JSONB columns\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mدين\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mدين\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(fix_json_field)\n\u001b[0;32m     31\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mمواضيع\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mمواضيع\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(fix_json_field)\n\u001b[0;32m     32\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mأحداث\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mأحداث\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(fix_json_field)\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\cudas\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\cudas\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'دين'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv('./CSV/FAZ3_POEMS_Exact_Search - Exact_search.csv', sep='\\t')  # Using tab separator\n",
    "\n",
    "def fix_json_field(value):\n",
    "    \"\"\"Convert various formats to proper JSON array\"\"\"\n",
    "    if pd.isna(value) or value == '' or value == '[]':\n",
    "        return '[]'\n",
    "    \n",
    "    value_str = str(value).strip()\n",
    "    \n",
    "    # If it already looks like a JSON array, return as-is\n",
    "    if value_str.startswith('[') and value_str.endswith(']'):\n",
    "        try:\n",
    "            # Test if it's valid JSON\n",
    "            json.loads(value_str)\n",
    "            return value_str\n",
    "        except:\n",
    "            # If not valid JSON, treat as comma-separated\n",
    "            pass\n",
    "    \n",
    "    # Handle comma-separated values\n",
    "    if ',' in value_str:\n",
    "        items = [item.strip().strip('\"') for item in value_str.split(',')]\n",
    "        return json.dumps(items, ensure_ascii=False)\n",
    "    else:\n",
    "        # Single value - wrap in array\n",
    "        return json.dumps([value_str], ensure_ascii=False)\n",
    "\n",
    "# Apply fixes to JSONB columns\n",
    "df['دين'] = df['دين'].apply(fix_json_field)\n",
    "df['مواضيع'] = df['مواضيع'].apply(fix_json_field)\n",
    "df['أحداث'] = df['أحداث'].apply(fix_json_field)\n",
    "df['أماكن'] = df['أماكن'].apply(fix_json_field)\n",
    "\n",
    "# Keep 'شخص' as-is since it's already proper JSON format\n",
    "# Verify that 'person' field is properly formatted (it should be like [{\"name\":\"...\"}])\n",
    "def verify_person_format(value):\n",
    "    if pd.isna(value) or value == '' or value == '[]':\n",
    "        return '[]'\n",
    "    \n",
    "    value_str = str(value).strip()\n",
    "    if value_str.startswith('[') and value_str.endswith(']'):\n",
    "        try:\n",
    "            json.loads(value_str)\n",
    "            return value_str\n",
    "        except:\n",
    "            return '[]'\n",
    "    else:\n",
    "        return '[]'\n",
    "\n",
    "df['شخص'] = df['شخص'].apply(verify_person_format)\n",
    "\n",
    "# Save the corrected CSV\n",
    "df.to_csv('corrected_file.csv', sep='\\t', index=False, encoding='utf-8')\n",
    "print(\"CSV fixed successfully! Ready for upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef232ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['poem_id', 'Row_ID', 'Title_raw', 'Poem_line_raw', 'summary', 'Title_cleaned', 'Poem_line_cleaned', 'قافية', 'روي', 'البحر', 'وصل', 'حركة', 'شخص', 'sentiments', 'أحداث', 'دين', 'مواضيع', 'أماكن', 'تصنيف']\n",
      "\n",
      "Sample data:\n",
      "   poem_id  Row_ID     Title_raw  \\\n",
      "0        1       1  لا تسال مجرب   \n",
      "1        1       2  لا تسال مجرب   \n",
      "\n",
      "                                       Poem_line_raw  \\\n",
      "0  أنـانـي فْـ وصـلك لـكـن يالأنـاني      تـرى ال...   \n",
      "1  لحظات حبّـك حطّـمت لي كـياني      والحزن من بي...   \n",
      "\n",
      "                                             summary Title_cleaned  \\\n",
      "0  يعترف بأنانية في وصلها، محذرًا أن الأنانية في ...  لا تسال مجرب   \n",
      "1  لحظات الحب دمرت كيانه، وأدت إلى تسرب الحزن الع...  لا تسال مجرب   \n",
      "\n",
      "                                   Poem_line_cleaned قافية روي    البحر  \\\n",
      "0  اناني ف وصلك لكن يالاناني      تري الانانيه ف ...    رب   ب  الهجيني   \n",
      "1  لحظات حبك حطمت لي كياني      والحزن من بين الم...    رب   ب  الهجيني   \n",
      "\n",
      "       وصل  حركة                                                شخص  \\\n",
      "0  لا يوجد  فتحة  [{\"name\":\"الحبيب\",\"relation\":\"المحبوب\",\"resolv...   \n",
      "1  لا يوجد  فتحة  [{\"name\":\"الحبيب\",\"relation\":\"المحبوب\",\"resolv...   \n",
      "\n",
      "  sentiments أحداث دين                             مواضيع أماكن  تصنيف  \n",
      "0        غضب    []  []  [\"الحب والغزل\", \"الغيرة والعتاب\"]    []  معاصر  \n",
      "1        حزن    []  []          الحب والغزل, الألم والحزن    []  معاصر  \n",
      "CSV fixed successfully! Ready for upload.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('./CSV/FAZ3_POEMS_Exact_Search - Exact_search.csv', encoding='utf-8')  # comma-separated\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head(2))\n",
    "\n",
    "def fix_json_field(value):\n",
    "    \"\"\"Convert various formats to proper JSON array\"\"\"\n",
    "    if pd.isna(value) or value == '' or value == '[]':\n",
    "        return '[]'\n",
    "    \n",
    "    value_str = str(value).strip()\n",
    "    \n",
    "    # If it already looks like a JSON array, return as-is\n",
    "    if value_str.startswith('[') and value_str.endswith(']'):\n",
    "        try:\n",
    "            # Test if it's valid JSON\n",
    "            json.loads(value_str)\n",
    "            return value_str\n",
    "        except:\n",
    "            # If not valid JSON, treat as comma-separated\n",
    "            pass\n",
    "    \n",
    "    # Handle comma-separated values\n",
    "    if ',' in value_str:\n",
    "        items = [item.strip().strip('\"') for item in value_str.split(',')]\n",
    "        return json.dumps(items, ensure_ascii=False)\n",
    "    else:\n",
    "        # Single value - wrap in array\n",
    "        return json.dumps([value_str], ensure_ascii=False)\n",
    "\n",
    "# Apply fixes to JSONB columns\n",
    "df['دين'] = df['دين'].apply(fix_json_field)\n",
    "df['مواضيع'] = df['مواضيع'].apply(fix_json_field)\n",
    "df['أحداث'] = df['أحداث'].apply(fix_json_field)\n",
    "df['أماكن'] = df['أماكن'].apply(fix_json_field)\n",
    "\n",
    "# Keep 'شخص' as-is since it's already proper JSON format\n",
    "def verify_person_format(value):\n",
    "    if pd.isna(value) or value == '' or value == '[]':\n",
    "        return '[]'\n",
    "    \n",
    "    value_str = str(value).strip()\n",
    "    if value_str.startswith('[') and value_str.endswith(']'):\n",
    "        try:\n",
    "            json.loads(value_str)\n",
    "            return value_str\n",
    "        except:\n",
    "            return '[]'\n",
    "    else:\n",
    "        return '[]'\n",
    "\n",
    "df['شخص'] = df['شخص'].apply(verify_person_format)\n",
    "\n",
    "# Save the corrected CSV\n",
    "df.to_csv('corrected_file.csv', index=False, encoding='utf-8')\n",
    "print(\"CSV fixed successfully! Ready for upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4364f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76851346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
