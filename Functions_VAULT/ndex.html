<!DOCTYPE html>
<html lang="ar" dir="rtl">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Arabic Poetry Search — Full Verbose Dev Version</title>

    <!-- FlexSearch bundle (fast) -->
    <script src="https://cdn.jsdelivr.net/npm/flexsearch@0.7.31/dist/flexsearch.bundle.js"></script>

    <style>
      /* ===========================
     Visual layout - verbose styles
     =========================== */
      :root {
        --bg: #f9fafb;
        --card: #fff;
        --muted: #666;
        --accent: #ffd54f;
        --border: #e8e8e8;
        --text: #111;
        --radius: 10px;
      }
      html,
      body {
        height: 100%;
        margin: 0;
        padding: 0;
        direction: rtl;
        font-family: "Noto Naskh Arabic", "Segoe UI", "Helvetica Neue", Arial,
          sans-serif;
        background: var(--bg);
        color: var(--text);
      }
      .container {
        max-width: 920px;
        margin: 20px auto;
        padding: 18px;
      }
      h1 {
        margin: 0 0 10px 0;
        font-size: 20px;
        font-weight: 800;
        text-align: right;
      }
      .meta {
        font-size: 13px;
        color: var(--muted);
        margin-bottom: 12px;
        text-align: right;
      }
      .search-row {
        display: flex;
        gap: 8px;
        align-items: center;
        margin-bottom: 10px;
      }
      .search-input {
        flex: 1;
        padding: 12px 14px;
        border-radius: 10px;
        border: 1px solid var(--border);
        font-size: 18px;
        box-shadow: 0 6px 24px rgba(20, 20, 20, 0.03);
      }
      .controls {
        display: flex;
        gap: 8px;
        align-items: center;
      }
      .btn {
        padding: 8px 12px;
        border-radius: 8px;
        border: 1px solid var(--border);
        background: var(--card);
        cursor: pointer;
        font-size: 14px;
      }
      .small {
        font-size: 13px;
        color: var(--muted);
      }
      .dropdown {
        position: relative;
        margin-top: 6px;
      }
      .dropdown-box {
        position: absolute;
        right: 0;
        left: 0;
        max-height: 420px;
        overflow: auto;
        background: var(--card);
        border-radius: 12px;
        border: 1px solid var(--border);
        box-shadow: 0 12px 40px rgba(19, 19, 19, 0.06);
        z-index: 40;
      }
      .result-item {
        padding: 12px;
        border-bottom: 1px solid #f4f4f4;
        cursor: pointer;
      }
      .result-item:hover {
        background: #fbfbfb;
      }
      .title {
        font-weight: 800;
        margin-bottom: 6px;
      }
      .line {
        line-height: 1.7;
        color: var(--text);
        font-size: 15px;
      }
      mark {
        background: var(--accent);
        padding: 0 3px;
        border-radius: 3px;
      }
      .detail-card {
        margin-top: 18px;
        background: var(--card);
        border: 1px solid var(--border);
        padding: 14px;
        border-radius: 12px;
      }
      .debug {
        margin-top: 10px;
        font-size: 13px;
        color: #444;
        background: #fff;
        padding: 10px;
        border-radius: 8px;
        border: 1px dashed #eee;
      }
      .badge {
        display: inline-block;
        padding: 4px 8px;
        border-radius: 8px;
        background: #f3f3f3;
        margin-left: 6px;
        font-size: 12px;
        color: var(--muted);
      }
      .loader {
        display: inline-block;
        width: 16px;
        height: 16px;
        border-radius: 50%;
        border: 3px solid #eee;
        border-top-color: var(--muted);
        animation: spin 1s linear infinite;
        vertical-align: middle;
      }
      @keyframes spin {
        to {
          transform: rotate(360deg);
        }
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Arabic Poetry Search — Sandbox (Verbose Developer Edition)</h1>
      <div class="meta">
        وضع التجربة المحلي — ضع <code>index.html</code> و<code>poems.csv</code>
        في نفس المجلد ثم شغّل خادم محلي (مثال:
        <code>python -m http.server 8000</code>).
        <span class="badge">تعرض النتائج 10 مبدئياً — مرر لعرض المزيد</span>
      </div>

      <div class="search-row">
        <input
          id="inp"
          class="search-input"
          type="search"
          placeholder="اكتب جزءاً من الكلمة أو الجملة (مثال: را)"
          autocomplete="off"
        />
        <div class="controls">
          <button id="clearBtn" class="btn">مسح</button>
          <button id="debugBtn" class="btn">عرض سجلات التحميل</button>
        </div>
      </div>

      <div
        id="dropdownContainer"
        class="dropdown"
        aria-haspopup="listbox"
        aria-expanded="false"
        style="display: none"
      >
        <div id="dropdown" class="dropdown-box" role="listbox"></div>
      </div>

      <div id="detail" class="detail-card" style="display: none"></div>

      <div id="debugPanel" class="debug" style="display: none"></div>
    </div>

    <script>
      /* ============================================================================
   FULL VERBOSE SEARCH APP (FlexSearch) - Developer friendly expanded version
   ----------------------------------------------------------------------------
   Features:
   - Loads CSV/TSV with header detection
   - Builds FlexSearch.Document index on pre-cleaned or normalized fields
   - Arabic normalization (tashkeel/tatweel removal, alef/yaa/hamza handling)
   - Exact/prefix/contains boosting to prioritize full matches (fixes محمد vs حمد)
   - Boost list (up to 100 words)
   - Deduplication (never return duplicates)
   - Returns context: previous/current/next line within the same poem_id
   - Dropdown shows initial 10 items, scroll to load more
   - Click -> detail view with highlighted tokens in title & text
   - Verbose console logs & debug panel in UI
   ============================================================================ */

      /* ---------------------------
   Configuration
   --------------------------- */
      const DATA_FILE = "poems.csv"; // file must be in same folder as HTML
      const EXPECTED_HEADERS = [
        "Row_number",
        "poem_id",
        "Title",
        "Text content",
        "Title_cleaned",
        "Text_cleaned",
      ];
      const INITIAL_SHOW = 10;
      const LOAD_MORE = 10; // chunk to append when scrolling

      // BOOST WORDS - editable up to 100 words
      const BOOSTED_WORDS = [
        "محمد",
        "راشد",
        "حب",
        "عشق",
        "قلب",
        "ليل",
        "الوطن",
        "امارات",
        "حمد",
        "احمد",
        // add more words...
      ];

      /* ---------------------------
   Global state
   --------------------------- */
      let RAW_ROWS = []; // raw parsed rows (objects)
      let LINES = []; // normalized line objects with index mapping
      let GROUPS = {}; // poem_id => [lineIdx,...]
      let flexIndex = null; // FlexSearch.Document instance

      // UI state
      const inp = document.getElementById("inp");
      const dropdownContainer = document.getElementById("dropdownContainer");
      const dropdown = document.getElementById("dropdown");
      const detail = document.getElementById("detail");
      const debugPanel = document.getElementById("debugPanel");
      const clearBtn = document.getElementById("clearBtn");
      const debugBtn = document.getElementById("debugBtn");

      let activeResults = []; // ordered array of result objects (unique by idx)
      let shownCount = 0; // how many items currently shown in dropdown

      /* ============================
   Utility: Logging & debug
   ============================ */
      function logDebug(msg) {
        console.log("[search-dev] " + msg);
      }
      function showDebugPanel(text) {
        debugPanel.style.display = "block";
        debugPanel.innerHTML = `<pre style="white-space:pre-wrap;">${escapeHtml(
          text
        )}</pre>`;
      }

      /* ============================
   Utility: HTML escape
   ============================ */
      function escapeHtml(s) {
        if (s === undefined || s === null) return "";
        return String(s)
          .replace(/&/g, "&amp;")
          .replace(/</g, "&lt;")
          .replace(/>/g, "&gt;");
      }

      /* ============================
   CSV/TSV Loader (robust)
   - detects delimiter based on header line
   - supports quoted fields
   - returns array of objects keyed by header
   ============================ */
      async function loadDataFile(path) {
        logDebug("Fetching data file: " + path);
        const res = await fetch(path);
        if (!res.ok)
          throw new Error("Failed to fetch " + path + " (" + res.status + ")");
        const raw = await res.text();

        // remove BOM if present
        const text = raw.replace(/^\uFEFF/, "");

        // split into lines but preserve quoted newlines (simple approach)
        // We'll split by \n and handle quoted commas/tabs when parsing columns
        const lines = text.split(/\r?\n/).filter((l) => l.trim().length > 0);
        if (lines.length < 2) {
          throw new Error("File looks too small or empty: " + path);
        }

        // detect delimiter by checking first line (header)
        const headerLine = lines[0];
        const delimiter = headerLine.includes("\t") ? "\t" : ",";

        const headers = parseCsvLine(headerLine, delimiter).map((h) =>
          h.trim()
        );
        logDebug(
          "Detected delimiter: " +
            (delimiter === "\t" ? "\\t" : "comma") +
            " ; headers: " +
            JSON.stringify(headers)
        );

        const rows = [];
        for (let i = 1; i < lines.length; i++) {
          // naive: join until we have same number of columns (handles quoted newlines poorly but OK for most CSVs)
          const parsed = parseCsvLine(lines[i], delimiter);
          // if parsed shorter than header, attempt to append next lines until lengths match (simple heuristic)
          let j = i;
          while (parsed.length < headers.length && j < lines.length - 1) {
            j++;
            const combined = lines.slice(i, j + 1).join("\n");
            const reparsed = parseCsvLine(combined, delimiter);
            if (reparsed.length === headers.length) {
              parsed.length = 0;
              parsed.push(...reparsed);
              i = j; // advance main loop
              break;
            }
            if (j === lines.length - 1) break;
          }
          // build object keyed by header
          const obj = {};
          for (let k = 0; k < headers.length; k++) {
            obj[headers[k]] = parsed[k] !== undefined ? parsed[k] : "";
          }
          rows.push(obj);
        }

        logDebug("Parsed rows: " + rows.length);
        return { headers, rows };
      }

      // parse a CSV/TSV line into columns (handles quoted fields with escaped quotes)
      function parseCsvLine(line, delimiter) {
        const cols = [];
        let cur = "";
        let inQuotes = false;
        for (let i = 0; i < line.length; i++) {
          const ch = line[i];
          if (ch === '"') {
            // handle double quotes inside quoted field
            if (inQuotes && i + 1 < line.length && line[i + 1] === '"') {
              cur += '"';
              i++;
              continue;
            }
            inQuotes = !inQuotes;
            continue;
          }
          if (!inQuotes && ch === delimiter) {
            cols.push(cur);
            cur = "";
            continue;
          }
          cur += ch;
        }
        cols.push(cur);
        return cols;
      }

      /* ============================
   Arabic Normalization functions
   - explicit, well documented
   ============================ */

      /*
  Normalization steps applied:
  1) Remove Arabic diacritics (tashkeel) U+0610–U+061A, U+064B–U+065F and more
  2) Remove tatweel (kashida) U+0640
  3) Normalize alef variants to plain ا
  4) Normalize alif maqsura (ى) to ي
  5) Normalize hamza variants to bare hamza ء (or keep as ء)
  6) Normalize taa marbouta handling (kept as ة to be safer)
  7) Remove punctuation that interferes with tokenization
  8) Collapse multiple spaces
*/
      function removeDiacriticsAndNormalize(str) {
        if (!str) return "";
        let s = String(str);

        // Remove diacritics / tashkeel
        // This range covers many Arabic diacritics (common ones included)
        s = s.replace(/[\u0610-\u061A\u064B-\u065F\u06D6-\u06ED]/g, "");

        // Remove tatweel (kashida)
        s = s.replace(/\u0640/g, "");

        // Normalize alef forms to ا
        s = s.replace(/[إأآا]/g, "ا");

        // Normalize alif maqsura to ي
        s = s.replace(/ى/g, "ي");

        // Normalize certain hamza forms to ء (kept simple)
        s = s.replace(/[ؤئ]/g, "ء");

        // Optionally normalize taa marbouta (leave as ة by default)
        // s = s.replace(/ة/g,"ه");

        // Remove punctuation (Arabic and Latin common punctuation)
        s = s.replace(/[.,\/#!$%\^&\*;:{}=\-_`~()؟٬«»"”“'’\-–—]/g, " ");

        // Collapse whitespace
        s = s.replace(/\s+/g, " ").trim();

        return s;
      }

      // helper: full normalization wrapper (for indexing/search)
      function normalizedFieldForIndex(rawCandidate) {
        // Prefer the provided cleaned column if non-empty (allows pre-cleaned CSV)
        if (rawCandidate && String(rawCandidate).trim().length > 0) {
          return removeDiacriticsAndNormalize(rawCandidate);
        }
        return removeDiacriticsAndNormalize(rawCandidate || "");
      }

      /* ============================
   Build LINES structure + GROUPS + FlexSearch index
   - verbose and explicit for easy debugging & modifications
   ============================ */
      function buildIndexFromRows(headers, rows) {
        RAW_ROWS = rows; // store raw rows for debug
        LINES = [];
        GROUPS = {};

        // If CSV headers have the expected names, use them, otherwise attempt to map by heuristic
        const colRowNum = headers.includes("Row_number")
          ? "Row_number"
          : headers[0];
        const colPoemId = headers.includes("poem_id")
          ? "poem_id"
          : headers.includes("poemId")
          ? "poemId"
          : headers[1];
        const colTitle = headers.includes("Title") ? "Title" : headers[2];
        const colText = headers.includes("Text content")
          ? "Text content"
          : headers[3];
        const colTitleClean = headers.includes("Title_cleaned")
          ? "Title_cleaned"
          : headers.includes("title_clean")
          ? "title_clean"
          : null;
        const colTextClean = headers.includes("Text_cleaned")
          ? "Text_cleaned"
          : headers.includes("text_clean")
          ? "text_clean"
          : null;

        logDebug(
          "Column mapping -> rowNum:" +
            colRowNum +
            " poem_id:" +
            colPoemId +
            " title:" +
            colTitle +
            " text:" +
            colText +
            " title_clean:" +
            colTitleClean +
            " text_clean:" +
            colTextClean
        );

        // build LINES array with normalized fields
        for (let i = 0; i < rows.length; i++) {
          const r = rows[i];
          const rowNumber =
            r[colRowNum] !== undefined ? r[colRowNum] : String(i + 1);
          const poemId = String(
            r[colPoemId] !== undefined ? r[colPoemId] : "0"
          );
          const titleRaw = r[colTitle] !== undefined ? r[colTitle] : "";
          const textRaw = r[colText] !== undefined ? r[colText] : "";

          // prefer provided cleaned columns if available, otherwise compute
          const titleCleanSrc = colTitleClean ? r[colTitleClean] || "" : "";
          const textCleanSrc = colTextClean ? r[colTextClean] || "" : "";

          const titleClean =
            titleCleanSrc && titleCleanSrc.trim().length > 0
              ? removeDiacriticsAndNormalize(titleCleanSrc)
              : removeDiacriticsAndNormalize(titleRaw);
          const textClean =
            textCleanSrc && textCleanSrc.trim().length > 0
              ? removeDiacriticsAndNormalize(textCleanSrc)
              : removeDiacriticsAndNormalize(textRaw);

          const obj = {
            idx: i,
            Row_number: rowNumber,
            poem_id: poemId,
            Title_raw: titleRaw,
            Text_raw: textRaw,
            title_clean: titleClean,
            text_clean: textClean,
          };
          LINES.push(obj);

          // group by poem_id preserving order
          if (!GROUPS[poemId]) GROUPS[poemId] = [];
          GROUPS[poemId].push(i);
        }

        // DEBUG
        logDebug(
          "LINES constructed: " +
            LINES.length +
            " lines across " +
            Object.keys(GROUPS).length +
            " poems"
        );

        // Build FlexSearch.Document index with explicit configuration
        // We'll store both clean fields and also keep Title_raw/Text_raw in store
        flexIndex = new FlexSearch.Document({
          document: {
            id: "idx",
            store: [
              "poem_id",
              "Title_raw",
              "Text_raw",
              "Row_number",
              "title_clean",
              "text_clean",
            ],
            index: [
              { field: "title_clean", tokenize: "forward", weight: 3 },
              { field: "text_clean", tokenize: "forward", weight: 1 },
            ],
          },
          tokenize: "forward",
          cache: true,
          preset: "match",
        });

        // add documents to index (explicit normalized fields)
        for (const line of LINES) {
          const doc = {
            idx: line.idx,
            title_clean: line.title_clean,
            text_clean: line.text_clean,
            poem_id: line.poem_id,
            Title_raw: line.Title_raw,
            Text_raw: line.Text_raw,
            Row_number: line.Row_number,
          };
          flexIndex.add(doc);
        }
        logDebug("FlexSearch index built and populated.");
      }

      /* ============================
   Search pipeline (verbose)
   Steps:
   1) Normalize query
   2) Query FlexSearch (enrich) to get candidate docs
   3) Deduplicate candidates (unique idx)
   4) Compute custom scoring:
        - exact full-word match in title/text -> large boost
        - prefix (startsWith) -> medium boost
        - contains -> smaller boost
        - boosted words present -> add small boost
        - length/distance penalty for ambiguous short matches (helps محمد vs حمد)
   5) Sort by score (desc)
   6) Return unique results with context (prev/current/next)
   ============================ */

      // normalize query
      function normalizeQuery(q) {
        return removeDiacriticsAndNormalize(q);
      }

      // levenshtein distance (small, standard impl) - used as tie-breaker optionally
      function levenshtein(a, b) {
        if (!a) return b ? b.length : 0;
        if (!b) return a.length;
        const m = a.length,
          n = b.length;
        const dp = Array.from({ length: m + 1 }, (_, i) => i);
        for (let j = 1; j <= n; j++) {
          let prev = dp[0];
          dp[0] = j;
          for (let i = 1; i <= m; i++) {
            const cur = dp[i];
            const cost = a[i - 1] === b[j - 1] ? 0 : 1;
            dp[i] = Math.min(dp[i] + 1, dp[i - 1] + 1, prev + cost);
            prev = cur;
          }
        }
        return dp[m];
      }

      // main search function
      function searchPipeline(rawQuery) {
        const q = String(rawQuery || "").trim();
        if (!q) return [];

        const normQ = normalizeQuery(q);
        if (!normQ) return [];

        // 1) FlexSearch search (enrich: true gives doc objects)
        // We'll search with a decent limit to gather candidates
        const rawResults = flexIndex.search(normQ, {
          enrich: true,
          limit: 500,
          suggest: true,
        });
        // rawResults is an array per index (for each field) -> flatten
        const candidateMap = new Map();
        for (const bucket of rawResults) {
          if (!bucket.result) continue;
          for (const r of bucket.result) {
            if (!candidateMap.has(r.id)) {
              // r.doc contains stored fields
              candidateMap.set(r.id, {
                idx: r.id,
                poem_id: r.doc.poem_id,
                title_clean: r.doc.title_clean || "",
                text_clean: r.doc.text_clean || "",
                Title_raw: r.doc.Title_raw || "",
                Text_raw: r.doc.Text_raw || "",
                Row_number: r.doc.Row_number || "",
              });
            }
          }
        }
        const candidates = Array.from(candidateMap.values());
        logDebug("Candidates from FlexSearch: " + candidates.length);

        // 2) Score each candidate with custom logic
        const scored = candidates.map((c) => {
          const s = computeScoreForCandidate(c, normQ);
          return { doc: c, score: s };
        });

        // 3) Sort by score desc, tie-breaker by levenshtein small distance then index order
        scored.sort((a, b) => {
          if (b.score !== a.score) return b.score - a.score;
          // tie-breaker: smaller levenshtein between title and query is better
          const da = levenshtein(a.doc.title_clean || "", normQ);
          const db = levenshtein(b.doc.title_clean || "", normQ);
          if (da !== db) return da - db;
          // stable: by idx lower first
          return a.doc.idx - b.doc.idx;
        });

        // 4) Dedupe (should already be unique by idx) and map to array of docs
        const unique = scored.map((s) => s.doc);
        logDebug("Scored & sorted candidates: " + unique.length);

        return unique;
      }

      // Compute score: heavy emphasis on exact match/prefix, then contains, then boost-words, length penalty
      function computeScoreForCandidate(doc, normQ) {
        // We'll use a base score and add/subtract
        let score = 0;
        const title = (doc.title_clean || "").toString();
        const text = (doc.text_clean || "").toString();

        // exact full-word (split tokens)
        // We'll check token boundaries (word boundaries) using simple split by spaces
        const titleTokens = title.split(" ").filter(Boolean);
        const textTokens = text.split(" ").filter(Boolean);

        // If any token equals normQ exactly -> massive boost
        if (titleTokens.includes(normQ)) {
          score += 120; // huge boost for exact word in title
        }
        if (textTokens.includes(normQ)) {
          score += 80; // exact word in text
        }

        // exact substring contains (title/text contains query anywhere)
        if (title.indexOf(normQ) !== -1) score += 60;
        if (text.indexOf(normQ) !== -1) score += 30;

        // prefix match (startsWith) gets additional boost
        if (title.startsWith(normQ)) score += 40;
        if (text.startsWith(normQ)) score += 20;

        // boosted words list presence (adds small increments)
        let boostCount = 0;
        for (const w of BOOSTED_WORDS) {
          if (!w) continue;
          const nw = removeDiacriticsAndNormalize(w);
          if (title.indexOf(nw) !== -1 || text.indexOf(nw) !== -1) boostCount++;
        }
        score += boostCount * 8;

        // small length penalty: very short titles that accidentally match many queries penalized slightly
        score -= Math.abs((title.length || 0) - normQ.length) * 0.5;

        // small penalty for matches that are too short in relation to query
        if (
          normQ.length >= 2 &&
          title.length < normQ.length &&
          text.length < normQ.length
        ) {
          score -= 8;
        }

        // favor title occurrences more heavily (already done above)
        return score;
      }

      /* ============================
   Context builder (prev/current/next) with same poem_id constraint
   - returns array of lines in order
   ============================ */
      function getContextForLineIdx(lineIdx) {
        const line = LINES[lineIdx];
        if (!line) return [];
        const pid = line.poem_id;
        const arr = GROUPS[pid] || [];
        const pos = arr.indexOf(lineIdx);
        const out = [];
        if (pos > 0) out.push(LINES[arr[pos - 1]]);
        out.push(line);
        if (pos < arr.length - 1) out.push(LINES[arr[pos + 1]]);
        return out;
      }

      /* ============================
   Highlighting tolerant function
   - builds a tolerant regex that tolerates diacritics/tatweel between characters
   - but highlights the actual substring in raw text (keeps original diacritics)
   ============================ */
      function tolerantRegexForToken(token) {
        // escape
        const esc = token.replace(/[-/\\^$*+?.()|[\]{}]/g, "\\$&");
        // allow any number of diacritics/tatweel between letters
        const parts = Array.from(esc).map(
          (ch) => ch + "[\\u0610-\\u061A\\u064B-\\u065F\\u06D6-\\u06ED\\u0640]*"
        );
        const pattern = parts.join("");
        return new RegExp(pattern, "gi");
      }

      // highlight occurrences in raw text (works for title & text), using tokens from normalized query
      function highlightRawWithQuery(raw, query) {
        if (!raw) return "";
        if (!query) return escapeHtml(raw);
        const normTokens = normalizeQuery(query).split(/\s+/).filter(Boolean);
        let out = escapeHtml(raw);

        for (const tk of normTokens) {
          if (!tk) continue;
          const rx = tolerantRegexForToken(tk);
          out = out.replace(rx, (match) => `<mark>${match}</mark>`);
        }
        return out;
      }

      /* ============================
   Dropdown rendering & infinite scroll logic
   - show initial chunk: INITIAL_SHOW
   - on scroll -> append LOAD_MORE items
   - ensure deduplication
   ============================ */

      function renderDropdown(results, query) {
        // results: array of doc objects (unique)
        // store globally
        activeResults = results;
        shownCount = Math.min(INITIAL_SHOW, activeResults.length);

        if (activeResults.length === 0) {
          dropdownContainer.style.display = "none";
          return;
        }

        dropdownContainer.style.display = "block";
        dropdown.innerHTML = "";
        appendDropdownChunk(query); // initial chunk
      }

      function appendDropdownChunk(query) {
        const start = dropdown.children.length;
        const end = Math.min(activeResults.length, start + LOAD_MORE);
        for (let i = start; i < end; i++) {
          const doc = activeResults[i];
          const idx = Number(doc.idx);
          const ctx = getContextForLineIdx(idx); // array of lines
          const titleRaw = doc.Title_raw || "";
          // build HTML for this item: title + 3-line context
          const itemHtml = `
      <div class="result-item" data-idx="${idx}" role="option" aria-selected="false">
        <div class="title">${highlightRawWithQuery(titleRaw, query)}</div>
        <div class="line">${ctx
          .map(
            (c, j) =>
              `<div>${highlightRawWithQuery(c.Text_raw || "", query)}</div>`
          )
          .join("")}</div>
      </div>
    `;
          dropdown.insertAdjacentHTML("beforeend", itemHtml);
        }
        // wire click handlers lazily (delegate will handle)
        // If more remains, we keep scroll to load more
      }

      /* click handler for dropdown items (delegation) */
      dropdown.addEventListener("click", (ev) => {
        const node = ev.target.closest(".result-item");
        if (!node) return;
        const idx = Number(node.dataset.idx);
        openDetailForIndex(idx, inp.value);
        // hide dropdown to focus on detail
        dropdownContainer.style.display = "none";
      });

      /* infinite scroll: load more when near bottom */
      dropdown.addEventListener("scroll", (ev) => {
        const el = ev.target;
        if (el.scrollTop + el.clientHeight >= el.scrollHeight - 6) {
          // append next chunk
          if (dropdown.children.length < activeResults.length) {
            appendDropdownChunk(inp.value);
          }
        }
      });

      /* ============================
   Detail view rendering
   - show title + context (prev/current/next)
   - highlight tokens in title & lines
   ============================ */
      function openDetailForIndex(idx, query) {
        const ctx = getContextForLineIdx(idx);
        if (!ctx || ctx.length === 0) return;
        const title = LINES[idx].Title_raw || "";
        const titleHtml = `<div style="font-weight:900; font-size:20px; margin-bottom:8px;">${highlightRawWithQuery(
          title,
          query
        )}</div>`;
        const linesHtml = ctx
          .map(
            (l) =>
              `<div style="margin-bottom:6px; font-size:16px;">${highlightRawWithQuery(
                l.Text_raw,
                query
              )}</div>`
          )
          .join("");
        const footer = `<div class="small" style="margin-top:10px;color:var(--muted)">poem_id: ${escapeHtml(
          LINES[idx].poem_id
        )} — Row: ${escapeHtml(LINES[idx].Row_number)}</div>`;
        detail.innerHTML = titleHtml + linesHtml + footer;
        detail.style.display = "block";
        // scroll to detail for visibility
        detail.scrollIntoView({ behavior: "smooth", block: "center" });
      }

      /* ============================
   Input handling & debounce
   ============================ */
      let debounceTimer = null;
      const DEBOUNCE_MS = 120;

      inp.addEventListener("input", (ev) => {
        const q = ev.target.value;
        if (debounceTimer) clearTimeout(debounceTimer);
        debounceTimer = setTimeout(() => {
          handleSearchInput(q);
        }, DEBOUNCE_MS);
      });

      function handleSearchInput(q) {
        if (!q || q.trim() === "") {
          dropdownContainer.style.display = "none";
          activeResults = [];
          shownCount = 0;
          return;
        }
        const results = searchPipeline(q); // returns array of docs
        // remove duplicates across lines (two lines with same poem_id and identical text maybe) - but already unique by idx
        // however, ensure we never return two results that have identical title+text raw combination (de-dup)
        const uniq = [];
        const seen = new Set();
        for (const r of results) {
          const key = (r.Title_raw || "") + "||" + (r.Text_raw || "");
          if (!seen.has(key)) {
            uniq.push(r);
            seen.add(key);
          }
        }
        renderDropdown(uniq, q);
      }

      /* ============================
   Helper Buttons
   ============================ */
      clearBtn.addEventListener("click", () => {
        inp.value = "";
        dropdownContainer.style.display = "none";
        detail.style.display = "none";
        activeResults = [];
      });

      debugBtn.addEventListener("click", () => {
        const msg = `Loaded lines: ${LINES.length}\nPoems: ${
          Object.keys(GROUPS).length
        }\nIndex built: ${!!flexIndex}\nSample line[0]: ${escapeHtml(
          JSON.stringify(LINES[0] || {})
        )}\nBoost words: ${JSON.stringify(BOOSTED_WORDS)}`;
        showDebugPanel(msg);
      });

      /* ============================
   Startup init
   - load file -> parse -> build index -> ready
   ============================ */
      (async function init() {
        try {
          const { headers, rows } = await loadDataFile(DATA_FILE);
          if (!rows || rows.length === 0) throw new Error("No rows loaded");
          buildIndexFromRows(headers, rows);
          logDebug("Initialization complete. Ready to search.");
          // for UX: show ready hint
          document
            .querySelector(".meta")
            .insertAdjacentHTML(
              "beforeend",
              `<span class="badge" style="margin-right:6px">جاهز</span>`
            );
        } catch (err) {
          console.error(err);
          document
            .querySelector(".meta")
            .insertAdjacentHTML(
              "beforeend",
              `<span class="badge" style="background:#ffd6d6;color:#900;margin-right:6px">فشل التحميل</span>`
            );
          showDebugPanel(
            "خطأ أثناء التحميل: " +
              err.message +
              "\nتأكد من تشغيل خادم محلي وأن ملف poems.csv موجود في نفس المجلد."
          );
        }
      })();

      /* ============================================================================
   End of file
   ============================================================================
*/
    </script>
  </body>
</html>
